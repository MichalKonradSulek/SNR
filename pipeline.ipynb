{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs classification\n",
    "\n",
    "Authors: Michał Sułek, Andrzej Przybylski, Łukasz Kostrzewa, Patrycja Cieplicka\n",
    "Date: 02.04.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagegenerator\n",
    "import analyzer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'images/subset'\n",
    "results_path = 'results'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.MobileNetV3((224,224),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nMobilenetV3small (Functional (None, 1024)              1529968   \n_________________________________________________________________\nreshape_9 (Reshape)          (None, 1, 1, 1024)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1, 1, 1024)        0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 1, 1, 3)           3075      \n_________________________________________________________________\nflatten (Flatten)            (None, 3)                 0         \n_________________________________________________________________\nactivation (Activation)      (None, 3)                 0         \n=================================================================\nTotal params: 1,533,043\nTrainable params: 593,923\nNon-trainable params: 939,120\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build_mobileNetV3_2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "______________________________________________________\n",
      "expanded_conv_3/project (Conv2D (None, 14, 14, 40)   3840        expanded_conv_3/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_3/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_3/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/expand (Conv2D) (None, 14, 14, 240)  9600        expanded_conv_3/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/expand/BatchNor (None, 14, 14, 240)  960         expanded_conv_4/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_5 (TFOpLam (None, 14, 14, 240)  0           expanded_conv_4/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) (None, 14, 14, 240)  0           re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 14, 14, 240)  0           tf.math.multiply_5[0][0]         \n",
      "                                                                 expanded_conv_4/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/depthwise (Dept (None, 14, 14, 240)  6000        multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/depthwise/Batch (None, 14, 14, 240)  960         expanded_conv_4/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_6 (TFOpLam (None, 14, 14, 240)  0           expanded_conv_4/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_6 (TFOpLambda) (None, 14, 14, 240)  0           re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 14, 14, 240)  0           tf.math.multiply_6[0][0]         \n",
      "                                                                 expanded_conv_4/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 240)          0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 1, 240)    0           expanded_conv_4/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 64)     15424       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 64)     0           expanded_conv_4/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 1, 1, 240)    15600       expanded_conv_4/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_7 (TFOpLam (None, 1, 1, 240)    0           expanded_conv_4/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 1, 1, 240)    0           tf.__operators__.add_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_7 (TFOpLambda) (None, 1, 1, 240)    0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/squeeze_excite/ (None, 14, 14, 240)  0           multiply_4[0][0]                 \n",
      "                                                                 tf.math.multiply_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/project (Conv2D (None, 14, 14, 40)   9600        expanded_conv_4/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_4/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_4/Add (Add)       (None, 14, 14, 40)   0           expanded_conv_3/project/BatchNorm\n",
      "                                                                 expanded_conv_4/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/expand (Conv2D) (None, 14, 14, 240)  9600        expanded_conv_4/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/expand/BatchNor (None, 14, 14, 240)  960         expanded_conv_5/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_8 (TFOpLam (None, 14, 14, 240)  0           expanded_conv_5/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_8 (TFOpLambda) (None, 14, 14, 240)  0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 14, 14, 240)  0           tf.math.multiply_8[0][0]         \n",
      "                                                                 expanded_conv_5/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/depthwise (Dept (None, 14, 14, 240)  6000        multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/depthwise/Batch (None, 14, 14, 240)  960         expanded_conv_5/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_9 (TFOpLam (None, 14, 14, 240)  0           expanded_conv_5/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 14, 14, 240)  0           tf.__operators__.add_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_9 (TFOpLambda) (None, 14, 14, 240)  0           re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 14, 14, 240)  0           tf.math.multiply_9[0][0]         \n",
      "                                                                 expanded_conv_5/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 240)          0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 1, 240)    0           expanded_conv_5/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 64)     15424       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 64)     0           expanded_conv_5/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 1, 1, 240)    15600       expanded_conv_5/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_10 (TFOpLa (None, 1, 1, 240)    0           expanded_conv_5/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 1, 1, 240)    0           tf.__operators__.add_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_10 (TFOpLambda (None, 1, 1, 240)    0           re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/squeeze_excite/ (None, 14, 14, 240)  0           multiply_6[0][0]                 \n",
      "                                                                 tf.math.multiply_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/project (Conv2D (None, 14, 14, 40)   9600        expanded_conv_5/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/project/BatchNo (None, 14, 14, 40)   160         expanded_conv_5/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_5/Add (Add)       (None, 14, 14, 40)   0           expanded_conv_4/Add[0][0]        \n",
      "                                                                 expanded_conv_5/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/expand (Conv2D) (None, 14, 14, 120)  4800        expanded_conv_5/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/expand/BatchNor (None, 14, 14, 120)  480         expanded_conv_6/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_11 (TFOpLa (None, 14, 14, 120)  0           expanded_conv_6/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 14, 14, 120)  0           tf.__operators__.add_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_11 (TFOpLambda (None, 14, 14, 120)  0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 14, 14, 120)  0           tf.math.multiply_11[0][0]        \n",
      "                                                                 expanded_conv_6/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/depthwise (Dept (None, 14, 14, 120)  3000        multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/depthwise/Batch (None, 14, 14, 120)  480         expanded_conv_6/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_12 (TFOpLa (None, 14, 14, 120)  0           expanded_conv_6/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 14, 14, 120)  0           tf.__operators__.add_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_12 (TFOpLambda (None, 14, 14, 120)  0           re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 14, 14, 120)  0           tf.math.multiply_12[0][0]        \n",
      "                                                                 expanded_conv_6/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 120)          0           multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 1, 1, 120)    0           expanded_conv_6/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 32)     3872        reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 32)     0           expanded_conv_6/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 1, 1, 120)    3960        expanded_conv_6/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_13 (TFOpLa (None, 1, 1, 120)    0           expanded_conv_6/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 1, 1, 120)    0           tf.__operators__.add_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_13 (TFOpLambda (None, 1, 1, 120)    0           re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/squeeze_excite/ (None, 14, 14, 120)  0           multiply_8[0][0]                 \n",
      "                                                                 tf.math.multiply_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/project (Conv2D (None, 14, 14, 48)   5760        expanded_conv_6/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_6/project/BatchNo (None, 14, 14, 48)   192         expanded_conv_6/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/expand (Conv2D) (None, 14, 14, 144)  6912        expanded_conv_6/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/expand/BatchNor (None, 14, 14, 144)  576         expanded_conv_7/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_14 (TFOpLa (None, 14, 14, 144)  0           expanded_conv_7/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 14, 14, 144)  0           tf.__operators__.add_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_14 (TFOpLambda (None, 14, 14, 144)  0           re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 14, 14, 144)  0           tf.math.multiply_14[0][0]        \n",
      "                                                                 expanded_conv_7/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/depthwise (Dept (None, 14, 14, 144)  3600        multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/depthwise/Batch (None, 14, 14, 144)  576         expanded_conv_7/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_15 (TFOpLa (None, 14, 14, 144)  0           expanded_conv_7/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 14, 14, 144)  0           tf.__operators__.add_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_15 (TFOpLambda (None, 14, 14, 144)  0           re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 14, 14, 144)  0           tf.math.multiply_15[0][0]        \n",
      "                                                                 expanded_conv_7/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 144)          0           multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 1, 1, 144)    0           expanded_conv_7/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 40)     5800        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 40)     0           expanded_conv_7/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 1, 1, 144)    5904        expanded_conv_7/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_16 (TFOpLa (None, 1, 1, 144)    0           expanded_conv_7/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 1, 1, 144)    0           tf.__operators__.add_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_16 (TFOpLambda (None, 1, 1, 144)    0           re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/squeeze_excite/ (None, 14, 14, 144)  0           multiply_10[0][0]                \n",
      "                                                                 tf.math.multiply_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/project (Conv2D (None, 14, 14, 48)   6912        expanded_conv_7/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/project/BatchNo (None, 14, 14, 48)   192         expanded_conv_7/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_7/Add (Add)       (None, 14, 14, 48)   0           expanded_conv_6/project/BatchNorm\n",
      "                                                                 expanded_conv_7/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/expand (Conv2D) (None, 14, 14, 288)  13824       expanded_conv_7/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/expand/BatchNor (None, 14, 14, 288)  1152        expanded_conv_8/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_17 (TFOpLa (None, 14, 14, 288)  0           expanded_conv_8/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 14, 14, 288)  0           tf.__operators__.add_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_17 (TFOpLambda (None, 14, 14, 288)  0           re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 14, 14, 288)  0           tf.math.multiply_17[0][0]        \n",
      "                                                                 expanded_conv_8/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise/pad ( (None, 17, 17, 288)  0           multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise (Dept (None, 7, 7, 288)    7200        expanded_conv_8/depthwise/pad[0][\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/depthwise/Batch (None, 7, 7, 288)    1152        expanded_conv_8/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_18 (TFOpLa (None, 7, 7, 288)    0           expanded_conv_8/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 7, 7, 288)    0           tf.__operators__.add_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_18 (TFOpLambda (None, 7, 7, 288)    0           re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 7, 7, 288)    0           tf.math.multiply_18[0][0]        \n",
      "                                                                 expanded_conv_8/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 288)          0           multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 1, 1, 288)    0           expanded_conv_8/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 72)     20808       reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 72)     0           expanded_conv_8/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 1, 1, 288)    21024       expanded_conv_8/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_19 (TFOpLa (None, 1, 1, 288)    0           expanded_conv_8/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 1, 1, 288)    0           tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_19 (TFOpLambda (None, 1, 1, 288)    0           re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/squeeze_excite/ (None, 7, 7, 288)    0           multiply_12[0][0]                \n",
      "                                                                 tf.math.multiply_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/project (Conv2D (None, 7, 7, 96)     27648       expanded_conv_8/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_8/project/BatchNo (None, 7, 7, 96)     384         expanded_conv_8/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/expand (Conv2D) (None, 7, 7, 576)    55296       expanded_conv_8/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/expand/BatchNor (None, 7, 7, 576)    2304        expanded_conv_9/expand[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_20 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_9/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_20 (TFOpLambda (None, 7, 7, 576)    0           re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_20[0][0]        \n",
      "                                                                 expanded_conv_9/expand/BatchNorm[\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/depthwise (Dept (None, 7, 7, 576)    14400       multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/depthwise/Batch (None, 7, 7, 576)    2304        expanded_conv_9/depthwise[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_21 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_9/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_21 (TFOpLambda (None, 7, 7, 576)    0           re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_21[0][0]        \n",
      "                                                                 expanded_conv_9/depthwise/BatchNo\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 576)          0           multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 1, 1, 576)    0           expanded_conv_9/squeeze_excite/Av\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 144)    83088       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 144)    0           expanded_conv_9/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 1, 1, 576)    83520       expanded_conv_9/squeeze_excite/Re\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_22 (TFOpLa (None, 1, 1, 576)    0           expanded_conv_9/squeeze_excite/Co\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 1, 1, 576)    0           tf.__operators__.add_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_22 (TFOpLambda (None, 1, 1, 576)    0           re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/squeeze_excite/ (None, 7, 7, 576)    0           multiply_14[0][0]                \n",
      "                                                                 tf.math.multiply_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/project (Conv2D (None, 7, 7, 96)     55296       expanded_conv_9/squeeze_excite/Mu\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/project/BatchNo (None, 7, 7, 96)     384         expanded_conv_9/project[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_9/Add (Add)       (None, 7, 7, 96)     0           expanded_conv_8/project/BatchNorm\n",
      "                                                                 expanded_conv_9/project/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/expand (Conv2D (None, 7, 7, 576)    55296       expanded_conv_9/Add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/expand/BatchNo (None, 7, 7, 576)    2304        expanded_conv_10/expand[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_23 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_10/expand/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_23 (TFOpLambda (None, 7, 7, 576)    0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_23[0][0]        \n",
      "                                                                 expanded_conv_10/expand/BatchNorm\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/depthwise (Dep (None, 7, 7, 576)    14400       multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/depthwise/Batc (None, 7, 7, 576)    2304        expanded_conv_10/depthwise[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_24 (TFOpLa (None, 7, 7, 576)    0           expanded_conv_10/depthwise/BatchN\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_24 (TFOpLambda (None, 7, 7, 576)    0           re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_24[0][0]        \n",
      "                                                                 expanded_conv_10/depthwise/BatchN\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 576)          0           multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 1, 1, 576)    0           expanded_conv_10/squeeze_excite/A\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 144)    83088       reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 144)    0           expanded_conv_10/squeeze_excite/C\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 1, 1, 576)    83520       expanded_conv_10/squeeze_excite/R\n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_25 (TFOpLa (None, 1, 1, 576)    0           expanded_conv_10/squeeze_excite/C\n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 1, 1, 576)    0           tf.__operators__.add_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_25 (TFOpLambda (None, 1, 1, 576)    0           re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/squeeze_excite (None, 7, 7, 576)    0           multiply_16[0][0]                \n",
      "                                                                 tf.math.multiply_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/project (Conv2 (None, 7, 7, 96)     55296       expanded_conv_10/squeeze_excite/M\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/project/BatchN (None, 7, 7, 96)     384         expanded_conv_10/project[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_10/Add (Add)      (None, 7, 7, 96)     0           expanded_conv_9/Add[0][0]        \n",
      "                                                                 expanded_conv_10/project/BatchNor\n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 576)    55296       expanded_conv_10/Add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1/BatchNorm (BatchNormaliz (None, 7, 7, 576)    2304        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_26 (TFOpLa (None, 7, 7, 576)    0           Conv_1/BatchNorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 7, 7, 576)    0           tf.__operators__.add_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_26 (TFOpLambda (None, 7, 7, 576)    0           re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 7, 7, 576)    0           tf.math.multiply_26[0][0]        \n",
      "                                                                 Conv_1/BatchNorm[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_2 (Conv2D)                 (None, 7, 7, 1024)   590848      multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_27 (TFOpLa (None, 7, 7, 1024)   0           Conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 7, 7, 1024)   0           tf.__operators__.add_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_27 (TFOpLambda (None, 7, 7, 1024)   0           re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 7, 7, 1024)   0           tf.math.multiply_27[0][0]        \n",
      "                                                                 Conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           multiply_18[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,529,968\n",
      "Trainable params: 590,848\n",
      "Non-trainable params: 939,120\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "MobilenetV3small (Functional (None, 1024)              1529968   \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1, 1, 3)           3075      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,533,043\n",
      "Trainable params: 593,923\n",
      "Non-trainable params: 939,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = imagegenerator.ImageGenerator(data_path, validation_split=0.2, seed=123, batch_size=batch_size, image_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 465 images belonging to 3 classes.\n",
      "Found 115 images belonging to 3 classes.\n",
      "Epoch 1/4\n",
      "15/15 [==============================] - 31s 2s/step - loss: 1.1877 - accuracy: 0.4094 - val_loss: 1.2207 - val_accuracy: 0.3478\n",
      "Epoch 2/4\n",
      "15/15 [==============================] - 20s 1s/step - loss: 1.2182 - accuracy: 0.3167 - val_loss: 1.1583 - val_accuracy: 0.3304\n",
      "Epoch 3/4\n",
      "15/15 [==============================] - 20s 1s/step - loss: 1.1304 - accuracy: 0.3542 - val_loss: 1.1257 - val_accuracy: 0.3304\n",
      "Epoch 4/4\n",
      "15/15 [==============================] - 20s 1s/step - loss: 1.1077 - accuracy: 0.3630 - val_loss: 1.1991 - val_accuracy: 0.3304\n"
     ]
    }
   ],
   "source": [
    "history = model.train_with_generator(image_generator, 4, callbacks= [callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.train_with_arrays(image_generator, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 143 files belonging to 3 classes.\n",
      "model_2c metrics:\n",
      "accuracy: 0.329\n",
      "2-accuracy: 0.650\n",
      "confusion matrics:\n",
      " [[ 0 50  0]\n",
      " [ 0 47  0]\n",
      " [ 0 46  0]]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"484.57625pt\" version=\"1.1\" viewBox=\"0 0 553.659687 484.57625\" width=\"553.659687pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-03T11:03:24.984726</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 484.57625 \nL 553.659687 484.57625 \nL 553.659687 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 111.579688 473.87625 \nL 546.459687 473.87625 \nL 546.459687 38.99625 \nL 111.579688 38.99625 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p7ebe368bbb)\">\n    <image height=\"435\" id=\"image3a2568e6b6\" transform=\"scale(1 -1)translate(0 -435)\" width=\"435\" x=\"111.579688\" xlink:href=\"data:image/png;base64,\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\" y=\"-38.87625\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m1330c85b99\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"184.059687\" xlink:href=\"#m1330c85b99\" y=\"473.87625\"/>\n      </g>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 -3.5 \n\" id=\"m73280d2f5d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"184.059687\" xlink:href=\"#m73280d2f5d\" y=\"38.99625\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- Maltese dog -->\n      <g transform=\"translate(153.577656 29.916562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n        <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n        <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n        <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n        <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n        <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n        <path id=\"DejaVuSans-32\"/>\n        <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n        <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n        <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-77\"/>\n       <use x=\"86.279297\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"147.558594\" xlink:href=\"#DejaVuSans-108\"/>\n       <use x=\"175.341797\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"214.550781\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"276.074219\" xlink:href=\"#DejaVuSans-115\"/>\n       <use x=\"328.173828\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"389.697266\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"421.484375\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"484.960938\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"546.142578\" xlink:href=\"#DejaVuSans-103\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"329.019687\" xlink:href=\"#m1330c85b99\" y=\"473.87625\"/>\n      </g>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"329.019687\" xlink:href=\"#m73280d2f5d\" y=\"38.99625\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- Afghan hound -->\n      <g transform=\"translate(294.115781 29.916562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n        <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n        <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n        <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n        <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-65\"/>\n       <use x=\"64.783203\" xlink:href=\"#DejaVuSans-102\"/>\n       <use x=\"99.988281\" xlink:href=\"#DejaVuSans-103\"/>\n       <use x=\"163.464844\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"226.84375\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"288.123047\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"351.501953\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"383.289062\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"446.667969\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"507.849609\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"571.228516\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"634.607422\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"473.979687\" xlink:href=\"#m1330c85b99\" y=\"473.87625\"/>\n      </g>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"473.979687\" xlink:href=\"#m73280d2f5d\" y=\"38.99625\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- Scottish deerhound -->\n      <g transform=\"translate(425.289844 29.916562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n        <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n        <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n        <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-83\"/>\n       <use x=\"63.476562\" xlink:href=\"#DejaVuSans-99\"/>\n       <use x=\"118.457031\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"179.638672\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"218.847656\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"258.056641\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"285.839844\" xlink:href=\"#DejaVuSans-115\"/>\n       <use x=\"337.939453\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"401.318359\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"433.105469\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"496.582031\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"558.105469\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"619.628906\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"658.992188\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"722.371094\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"783.552734\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"846.931641\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"910.310547\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3a695cc1cf\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"111.579688\" xlink:href=\"#m3a695cc1cf\" y=\"111.47625\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- Maltese dog -->\n      <g transform=\"translate(43.615625 115.275469)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-77\"/>\n       <use x=\"86.279297\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"147.558594\" xlink:href=\"#DejaVuSans-108\"/>\n       <use x=\"175.341797\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"214.550781\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"276.074219\" xlink:href=\"#DejaVuSans-115\"/>\n       <use x=\"328.173828\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"389.697266\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"421.484375\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"484.960938\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"546.142578\" xlink:href=\"#DejaVuSans-103\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"111.579688\" xlink:href=\"#m3a695cc1cf\" y=\"256.43625\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- Afghan hound -->\n      <g transform=\"translate(34.771875 260.235469)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-65\"/>\n       <use x=\"64.783203\" xlink:href=\"#DejaVuSans-102\"/>\n       <use x=\"99.988281\" xlink:href=\"#DejaVuSans-103\"/>\n       <use x=\"163.464844\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"226.84375\" xlink:href=\"#DejaVuSans-97\"/>\n       <use x=\"288.123047\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"351.501953\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"383.289062\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"446.667969\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"507.849609\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"571.228516\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"634.607422\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"111.579688\" xlink:href=\"#m3a695cc1cf\" y=\"401.39625\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- Scottish deerhound -->\n      <g transform=\"translate(7.2 405.195469)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-83\"/>\n       <use x=\"63.476562\" xlink:href=\"#DejaVuSans-99\"/>\n       <use x=\"118.457031\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"179.638672\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"218.847656\" xlink:href=\"#DejaVuSans-116\"/>\n       <use x=\"258.056641\" xlink:href=\"#DejaVuSans-105\"/>\n       <use x=\"285.839844\" xlink:href=\"#DejaVuSans-115\"/>\n       <use x=\"337.939453\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"401.318359\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"433.105469\" xlink:href=\"#DejaVuSans-100\"/>\n       <use x=\"496.582031\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"558.105469\" xlink:href=\"#DejaVuSans-101\"/>\n       <use x=\"619.628906\" xlink:href=\"#DejaVuSans-114\"/>\n       <use x=\"658.992188\" xlink:href=\"#DejaVuSans-104\"/>\n       <use x=\"722.371094\" xlink:href=\"#DejaVuSans-111\"/>\n       <use x=\"783.552734\" xlink:href=\"#DejaVuSans-117\"/>\n       <use x=\"846.931641\" xlink:href=\"#DejaVuSans-110\"/>\n       <use x=\"910.310547\" xlink:href=\"#DejaVuSans-100\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 111.579688 473.87625 \nL 111.579688 38.99625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 546.459687 473.87625 \nL 546.459687 38.99625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 111.579688 473.87625 \nL 546.459687 473.87625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 111.579688 38.99625 \nL 546.459687 38.99625 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_7\">\n    <!-- Confusion matrix -->\n    <g transform=\"translate(277.710313 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"69.824219\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"131.005859\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"194.384766\" xlink:href=\"#DejaVuSans-102\"/>\n     <use x=\"229.589844\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"292.96875\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"345.068359\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"372.851562\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"434.033203\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"497.412109\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"529.199219\" xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"626.611328\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"687.890625\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"727.099609\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"768.212891\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"795.996094\" xlink:href=\"#DejaVuSans-120\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7ebe368bbb\">\n   <rect height=\"434.88\" width=\"434.88\" x=\"111.579688\" y=\"38.99625\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "labels = ['Maltese dog', 'Afghan hound',  'Scottish deerhound']\n",
    "an = analyzer.Analyzer(results_path)\n",
    "an.analyze_model(model, 'model_2a', image_generator, model_parameters=None, labels=labels, k=2, print_metrics=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}